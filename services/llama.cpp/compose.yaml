services:
  llama-cpp:
    labels:
      - traefik.enable=true
      - traefik.http.routers.llama.rule=Host(`llama.gryta.eu`)
      - traefik.http.routers.llama.entrypoints=websecure
      - traefik.http.routers.llama.tls.certresolver=le
      - traefik.http.services.llama.loadbalancer.server.port=8000
    image: ghcr.io/ggml-org/llama.cpp@sha256:e5325db45315e85c0292bbab77f6009fe94342a0441da979fcbc0fd0eaf1ecb4
    container_name: llama-cpp
    devices:
      - /dev/dri:/dev/dri
    volumes:
      - models:/models
    environment:
      LLAMA_ARG_MODEL: /models/nomic-embed-text-v1.5.Q8_0.gguf
      LLAMA_ARG_MODEL_URL: https://huggingface.co/nomic-ai/nomic-embed-text-v1.5-GGUF/resolve/main/nomic-embed-text-v1.5.Q8_0.gguf
      LLAMA_ARG_HOST: 0.0.0.0
      LLAMA_ARG_CTX_SIZE: 2048
      LLAMA_ARG_N_PARALLEL: 4
      LLAMA_ARG_ENDPOINT_METRICS: 1
      LLAMA_ARG_PORT: 8000
      LLAMA_ARG_EMBEDDINGS: 1
      LLAMA_ARG_POOLING: mean
      SYCL_CACHE_PERSISTENT: 1
      LLAMA_API_KEY: ${LLAMA_API_KEY}
      LLAMA_LOG_VERBOSITY: 2
    healthcheck:
      test:
        - CMD
        - curl
        - -f
        - http://localhost:8000/health
      interval: 1m
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      homelab-network:
        ipv4_address: 172.20.0.15
    restart: unless-stopped
volumes:
  models: null
networks:
  homelab-network:
    external: true
